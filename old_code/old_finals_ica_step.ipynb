{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ce2793-ab67-4281-8848-598389502f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2\n",
    "# # Assuming frames_gdf is a DataFrame containing information about each frame\n",
    "# # Assuming other dependencies (like plt) are imported elsewhere in your code\n",
    "# # \n",
    "# for index, row in frames_gdf.iterrows():\n",
    "#     frame = row['frame']\n",
    "#     restored_signals = row['subsiding_no_nans']\n",
    "#     dates = row['dates']\n",
    "#     restored_signals_3d = row['restored_signals_3d']\n",
    "#     restored_signals_full = row['restored_signals']\n",
    "#     corner_lat = row['corner_lat']\n",
    "#     corner_lon = row['corner_lon']\n",
    "#     post_lon = row['post_lon']\n",
    "#     post_lat = row['post_lat']\n",
    "#     width = row['width']\n",
    "#     height = row['length']\n",
    "#     lat = row['lat']\n",
    "#     lon = row['lon']\n",
    "#     nc_data = row['imdates']\n",
    "\n",
    "#     # Only proceed if there are enough coherent pixels\n",
    "#     if restored_signals[0].shape[1] >= 20:\n",
    "#         # List to store R-squared values for each trend\n",
    "#         mean_gradient = []\n",
    "#         median_r_squared = []\n",
    "#         median_dominant_period = []\n",
    "#         mean_second_derivative = []\n",
    "\n",
    "#         # Convert dates to numerical values\n",
    "#         num_dates = date2num(dates)\n",
    "\n",
    "#         for signal in restored_signals:\n",
    "#             r_squared_values = []\n",
    "#             gradient = []\n",
    "#             second_deriv = []\n",
    "#             dominant_periods = []\n",
    "\n",
    "#             # Loop through each trend at each pixel\n",
    "#             for i in range(signal.shape[1]):\n",
    "#                 # Perform linear regression and calculate R-squared\n",
    "#                 slope, _, r_value, _, _ = linregress(num_dates, signal[:, i])\n",
    "\n",
    "#                 # Store the gradient at each pixel\n",
    "#                 gradient.append(slope)\n",
    "\n",
    "#                 # Append R-squared value to the list\n",
    "#                 r_squared_values.append(r_value ** 2)\n",
    "\n",
    "#                 # Calculate the second derivative using numpy.gradient at each pixel\n",
    "#                 first_derivative = np.gradient(signal[:, i], num_dates)\n",
    "#                 second_deriv.append(np.gradient(first_derivative, num_dates))\n",
    "\n",
    "#                 # Perform FFT and find frequencies\n",
    "#                 fft_result = np.fft.fft(signal[:, i])\n",
    "\n",
    "#                 # Calculate the corresponding frequency using FFT frequencies\n",
    "#                 freqs = np.fft.fftfreq(len(signal[:, i]))\n",
    "#                 dominant_frequency = np.abs(freqs[np.argmax(np.abs(fft_result))])\n",
    "#                 dominant_period = 1 / dominant_frequency\n",
    "#                 dominant_periods.append(dominant_period)\n",
    "\n",
    "#             # take mean of gradients\n",
    "#             mean_gradient.append(np.mean(gradient))\n",
    "#             # take median of r_squared per IC\n",
    "#             median_r_squared.append(np.median(r_squared_values))\n",
    "#             # find median period of signal\n",
    "#             median_dominant_period.append(np.median(dominant_periods))\n",
    "#             # take mean of second derivative per IC\n",
    "#             mean_second_derivative.append(np.mean(second_deriv))\n",
    "\n",
    "#         # If mean gradient is negative, find the index of the trend with the maximum R-squared value\n",
    "#         negative_indices = [i for i, val in enumerate(mean_gradient) if val < 0]\n",
    "#         if negative_indices:\n",
    "#             median_r_squared_negative_gradients = [median_r_squared[i] for i in negative_indices]\n",
    "#             max_r_squared_negative_grad = np.max(median_r_squared_negative_gradients)\n",
    "#             max_index_in_median_r_squared = median_r_squared.index(max_r_squared_negative_grad)\n",
    "\n",
    "#             # Choose the signal\n",
    "#             inelastic_signal = restored_signals_3d[max_index_in_median_r_squared]\n",
    "#             inelastic_signal_subsiding = restored_signals[max_index_in_median_r_squared]\n",
    "\n",
    "#             # Save as NetCDF\n",
    "#             output_nc_dir = f\"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/inelastic_components/{ncomponents}_comp/\"\n",
    "#             if not os.path.exists(output_nc_dir):\n",
    "#                 os.makedirs(output_nc_dir)\n",
    "\n",
    "#             output_nc_path = os.path.join(output_nc_dir, f\"{frame}_inelastic_component_{ncomponents}.nc\")\n",
    "\n",
    "#             with nc.Dataset(output_nc_path, 'w') as file:\n",
    "#                 # Create dimensions\n",
    "#                 file.createDimension('dates', inelastic_signal.shape[0])\n",
    "#                 file.createDimension('latitude', inelastic_signal.shape[1])\n",
    "#                 file.createDimension('longitude', inelastic_signal.shape[2])\n",
    "\n",
    "#                 # Create variables\n",
    "#                 time_var = file.createVariable('dates', 'f4', ('dates',))\n",
    "#                 lat_var = file.createVariable('latitude', 'f4', ('latitude',))\n",
    "#                 lon_var = file.createVariable('longitude', 'f4', ('longitude',))\n",
    "#                 data_var = file.createVariable('data', 'f4', ('dates', 'latitude', 'longitude'))\n",
    "#                 period_var = file.createVariable('period', 'f4')\n",
    "#                 second_derivative_var = file.createVariable('second_derivative', 'f4')\n",
    "\n",
    "#                 # Add data to variables\n",
    "#                 time_var[:] = nc_data\n",
    "#                 lat_var[:] = lat\n",
    "#                 lon_var[:] = lon\n",
    "#                 data_var[:] = inelastic_signal\n",
    "#                 period_var[:] = median_dominant_period[max_index_in_median_r_squared]\n",
    "#                 second_derivative_var[:] = mean_second_derivative[max_index_in_median_r_squared]\n",
    "\n",
    "#             # Save as GeoTIFF\n",
    "#             output_tif_dir = f\"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/inelastic_components/{ncomponents}_comp/\"\n",
    "#             if not os.path.exists(output_tif_dir):\n",
    "#                 os.makedirs(output_tif_dir)\n",
    " \n",
    "#             # Create a transformation for the GeoTIFF\n",
    "#             transform = from_origin(corner_lon, corner_lat, post_lon, post_lat)\n",
    "\n",
    "#             output_tif_path = os.path.join(output_tif_dir, f\"{frame}_inelastic_component_{ncomponents}.tif\")\n",
    "#             flipped_data = np.flipud(inelastic_signal[-1, :, :])  # Assuming this is the correct data to flip\n",
    "\n",
    "#             with rasterio.open(output_tif_path, 'w', driver='GTiff', height=height, width=width, count=1,\n",
    "#                                dtype='float32', crs='EPSG:4326', transform=transform) as dst:\n",
    "#                 # Write the data to the GeoTIFF\n",
    "#                 dst.write(flipped_data, 1)\n",
    "\n",
    "#         # Save other signals as NetCDF\n",
    "#         output_nc_dir = f\"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/other_components/{ncomponents}_comp/{frame}\"\n",
    "#         if not os.path.exists(output_nc_dir):\n",
    "#             os.makedirs(output_nc_dir)\n",
    "\n",
    "#         output_nc_path = os.path.join(output_nc_dir, f\"other_component.nc\")\n",
    "\n",
    "#         with nc.Dataset(output_nc_path, 'w') as file:\n",
    "#             # Create dimensions\n",
    "#             file.createDimension('dates', inelastic_signal.shape[0])\n",
    "#             file.createDimension('latitude', inelastic_signal.shape[1])\n",
    "#             file.createDimension('longitude', inelastic_signal.shape[2])\n",
    "\n",
    "#             # Create variables\n",
    "#             time_var = file.createVariable('dates', 'f4', ('dates',))\n",
    "#             lat_var = file.createVariable('latitude', 'f4', ('latitude'))\n",
    "#             lon_var = file.createVariable('longitude', 'f4', ('longitude'))\n",
    "            \n",
    "#             # Create variables for each component\n",
    "#             data_vars = []\n",
    "#             period_vars = []\n",
    "#             second_derivative_vars = []\n",
    "\n",
    "#             for comp_index in range(ncomponents - 1):\n",
    "#                 data_var = file.createVariable(f'data_{comp_index}', 'f4', ('dates', 'latitude', 'longitude'))\n",
    "#                 period_var = file.createVariable(f'period_{comp_index}', 'f4')\n",
    "#                 second_derivative_var = file.createVariable(f'second_derivative_{comp_index}', 'f4')\n",
    "    \n",
    "#                 data_vars.append(data_var)\n",
    "#                 period_vars.append(period_var)\n",
    "#                 second_derivative_vars.append(second_derivative_var)\n",
    "\n",
    "#             # Add data, period, and second derivative to variables\n",
    "#             comp_index=0\n",
    "#             for i, signal_3d in enumerate(restored_signals_3d):\n",
    "#                 if i != max_index_in_median_r_squared:\n",
    "#                     data_vars[comp_index][:] = signal_3d\n",
    "#                     period_vars[comp_index][:] = median_dominant_period[i]\n",
    "#                     second_derivative_vars[comp_index][:] = mean_second_derivative[i]\n",
    "#                     comp_index += 1\n",
    "\n",
    "#             time_var[:] = nc_data\n",
    "#             lat_var[:] = lat\n",
    "#             lon_var[:] = lon\n",
    "\n",
    "#             # Save as GeoTIFF\n",
    "#             output_tif_dir = f\"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/other_components/{ncomponents}_comp/{frame}\"\n",
    "\n",
    "#             # Check if the directory exists\n",
    "#             if os.path.exists(output_tif_dir):\n",
    "#                 # Iterate over the files in the directory\n",
    "#                 for filename in os.listdir(output_tif_dir):\n",
    "#                 # Check if the file is a GeoTIFF\n",
    "#                     if filename.endswith(\".tif\"):\n",
    "#                         # Construct the full path to the file\n",
    "#                         file_path = os.path.join(output_tif_dir, filename)\n",
    "#                         # Delete the file\n",
    "#                         os.remove(file_path)\n",
    "#             else:\n",
    "#                 print(\"Directory does not exist.\")\n",
    "                \n",
    "#             for i, signal_3d in enumerate(restored_signals_3d):\n",
    "#                 if i != max_index_in_median_r_squared:\n",
    "#                     output_tif_path = os.path.join(output_tif_dir, f\"other_component_{i}.tif\")\n",
    "#                     flipped_final_disp_other = np.flipud(signal_3d[-1, :, :])  # Assuming this is the correct data to flip\n",
    "\n",
    "#                     with rasterio.open(output_tif_path, 'w', driver='GTiff', height=height, width=width, count=1,\n",
    "#                                        dtype='float32', crs='EPSG:4326', transform=transform) as dst:\n",
    "#                         # Write the data to the GeoTIFF\n",
    "#                         dst.write(flipped_final_disp_other, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0d6b5-4d16-49a6-9db7-abbcfc8257b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1\n",
    "# # find most linear!!  ## 30/04/24 backup\n",
    "\n",
    "# frames_gdf[\"inelastic_restored_signal_3d\"] = \"\"\n",
    "\n",
    "# for index, row in frames_gdf.iterrows():\n",
    "#     frame = row['frame']\n",
    "#     restored_signals = row['subsiding_no_nans']\n",
    "#     dates = row['dates']\n",
    "#     restored_signals_3d = row['restored_signals_3d']\n",
    "#     restored_signals_full = row['restored_signals']\n",
    "#     corner_lat = row['corner_lat']\n",
    "#     corner_lon = row['corner_lon']\n",
    "#     post_lon = row['post_lon']\n",
    "#     post_lat = row['post_lat']\n",
    "#     width = row['width']\n",
    "#     height = row['length']\n",
    "#     lat = row['lat']\n",
    "#     lon = row['lon']\n",
    "#     nc_data = row['imdates']\n",
    "\n",
    "#     # List to store R-squared values for each trend\n",
    "#     mean_gradient = []\n",
    "#     median_r_squared = []\n",
    "#     negative_indices = []\n",
    "#     median_r_squared_negative_gradients = []\n",
    "#     median_dominant_period = []\n",
    "#     mean_second_derivative = []\n",
    "#     second_derivatives_in_space = []\n",
    "    \n",
    "#     # Convert dates to numerical values\n",
    "#     num_dates = date2num(dates)\n",
    "#     if restored_signals[0].shape[1] > 20:\n",
    "#         for signal in restored_signals:\n",
    "#             r_squared_values = []\n",
    "#             gradient = []\n",
    "#             second_deriv = []\n",
    "#             dominant_frequencies = []\n",
    "#             dominant_periods = []\n",
    "\n",
    "#             # Loop through each trend at each pixel\n",
    "#             for i in range(signal.shape[1]):\n",
    "#                 # Create a time array from 0 to 197 (198 time steps)\n",
    "#                 time_steps = dates\n",
    "    \n",
    "#                 # Perform linear regression and calculate R-squared\n",
    "#                 slope, _, r_value, _, _ = linregress(num_dates, signal[:,i])\n",
    "            \n",
    "#                 # Store the gradient at each pixel\n",
    "#                 gradient.append(slope)\n",
    "\n",
    "#                 # Append R-squared value to the list\n",
    "#                 r_squared_values.append(r_value**2)\n",
    "\n",
    "#                 # Calculate the second derivative using numpy.gradient at each pixel\n",
    "#                 first_derivative = np.gradient(signal[:, i], num_dates)\n",
    "#                 second_deriv.append(np.gradient(first_derivative, num_dates))\n",
    "                \n",
    "#                 # Perform FFT and find frequencies\n",
    "#                 fft_result = np.fft.fft(signal[:, i])\n",
    "  \n",
    "#                 # Calculate the corresponding frequency using FFT frequencies\n",
    "#                 freqs = np.fft.fftfreq(len(signal[:, i]))\n",
    "#                 dominant_frequency = np.abs(freqs[np.argmax(np.abs(fft_result))])\n",
    "#                 dominant_period = 1/dominant_frequency\n",
    "#                 dominant_frequencies.append(dominant_frequency)\n",
    "#                 dominant_periods.append(dominant_period)\n",
    "        \n",
    "#             # take mean of gradients\n",
    "#             mean_gradient.append(np.mean(gradient))\n",
    "#             # take median of r_squared per IC\n",
    "#             median_r_squared.append(np.median(r_squared_values))\n",
    "#             # find median period of signal\n",
    "#             median_dominant_period.append(np.median(dominant_periods))\n",
    "#             # take mean of second derivative per IC\n",
    "#             mean_second_derivative.append(np.mean(second_deriv))\n",
    "#             # store second derivative at each pixel\n",
    "#             #second_derivatives_in_space.append(np.reshape(second_deriv, (\n",
    "\n",
    "#         print('median_r_squared:', median_r_squared)\n",
    "#         print('mean_gradient:', mean_gradient, 'mm/yr')\n",
    "#         print('median dominant period:', median_dominant_period, 'days')\n",
    "#         print('mean_second_derivative:', mean_second_derivative, 'days')\n",
    "    \n",
    "#         # If mean gradient is negative, find the index of the trend with the maximum R-squared value\n",
    "#         for i in range(len(mean_gradient)):\n",
    "#             if mean_gradient[i] < 0:\n",
    "#                 negative_indices.append(i)\n",
    "\n",
    "#         for n in negative_indices:\n",
    "#             median_r_squared_negative_gradients.append(median_r_squared[n])\n",
    "\n",
    "#         max_r_squared_negative_grad = np.max(median_r_squared_negative_gradients)\n",
    "\n",
    "#         # Find the index of max_median_r_squared_negative in median_r_squared\n",
    "#         max_index_in_median_r_squared = np.where(median_r_squared == max_r_squared_negative_grad)[0][0]\n",
    "#         print('index:', max_index_in_median_r_squared)\n",
    "    \n",
    "#         # choose the signal\n",
    "#         inelastic_signal = restored_signals_3d[max_index_in_median_r_squared]\n",
    "#         inelastic_signal_subsiding = restored_signals[max_index_in_median_r_squared]\n",
    "#         print('inelastic second_derivative:', mean_second_derivative[max_index_in_median_r_squared], 'mm/yr$^2$')\n",
    "        \n",
    "#         # Check tiff data chosen correctly\n",
    "#         fig, ax = plt.subplots()\n",
    "#         image = ax.imshow(inelastic_signal[-1,:,:], interpolation = 'none')\n",
    "#         colorbar = fig.colorbar(image)\n",
    "#         plt.show()\n",
    "    \n",
    "#         inelastic_signal_2d = restored_signals_full[max_index_in_median_r_squared]\n",
    "\n",
    "#         # Check time-series chosen correctly\n",
    "#         fig, ax = plt.subplots()\n",
    "#         print('shape of inelastic subsiding signal', inelastic_signal_subsiding.shape)\n",
    "#         for i in range(inelastic_signal_subsiding.shape[1]):\n",
    "#             ax.scatter(dates, inelastic_signal_subsiding[:, i])\n",
    "#             # Customize the plot as needed\n",
    "#             ax.set_xlabel('Date')\n",
    "#             ax.set_ylabel('Restored Signals')\n",
    "#             ax.set_title('Scatter Plot of Restored Signals Over Time')\n",
    "        \n",
    "#         frames_gdf.at[index, 'inelastic_restored_signal_3d'] = inelastic_signal\n",
    "\n",
    "#          # check in space it is subsidence pixels only\n",
    "\n",
    "#         for index, row in frames_gdf.iterrows():\n",
    "#             frame = row['frame']\n",
    "#             non_nan_ind = row['non_nan_ind']\n",
    "#             non_zero_ind = row['non_zero_ind']\n",
    "#             restored_signals_outer = row['restored_signals']\n",
    "#             cum = row['cum']\n",
    "#             lon_plot = row['lon']\n",
    "#             lat_plot = row['lat']\n",
    "#             common_indices = np.intersect1d(non_nan_ind, non_zero_ind)\n",
    "        \n",
    "#         # to save as tif, choose final timestep of 3d restored signal\n",
    "#         final_disp = inelastic_signal[-1,:,:]\n",
    "        \n",
    "#         # Flip the data vertically\n",
    "#         flipped_data = np.flipud(final_disp)\n",
    "    \n",
    "#         # Create a transformation for the GeoTIFF\n",
    "#         transform = from_origin(corner_lon, corner_lat, post_lon, post_lat)\n",
    "    \n",
    "#         output_nc_path = \"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/inelastic_components/{}_comp/{}_inelastic_component_{}.nc\".format(ncomponents, frame, ncomponents)\n",
    "#         output_tif_path = \"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/inelastic_components/{}_comp/{}_inelastic_component_{}.tif\".format(ncomponents, frame, ncomponents)\n",
    "        \n",
    "#         # Create a rasterio dataset and write the inelastic data to it\n",
    "#         with rasterio.open(output_tif_path, 'w', driver='GTiff', height=height, width=width, count=1, dtype='float32', crs='EPSG:4326', transform=transform) as dst:\n",
    "#             # Write the data to the GeoTIFF\n",
    "#             dst.write(flipped_data, 1)\n",
    "    \n",
    "#         # save the other components to tifs with indices\n",
    "#         output_directory = \"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/other_components_{}/{}\".format(ncomponents, frame)\n",
    "#         if not os.path.exists(output_directory):\n",
    "#             os.makedirs(output_directory)\n",
    "    \n",
    "#         # Remove existing GeoTIFF files in the directory\n",
    "#         for file_name in os.listdir(output_directory):\n",
    "#             if file_name.endswith(\".tif\"):\n",
    "#                 file_path = os.path.join(output_directory, file_name)\n",
    "#                 os.remove(file_path)\n",
    "\n",
    "#         # save other component tifs\n",
    "#         for i, signal in enumerate(restored_signals_3d):\n",
    "#             if i == max_index_in_median_r_squared:\n",
    "#                  continue # skip saving the signal with the inelastic index\n",
    "#             final_disp_other = signal[-1,:,:]\n",
    "#             print(i)\n",
    "#             flipped_final_disp_other = np.flipud(final_disp_other)\n",
    "#             path = os.path.join(output_directory, \"component_{}.tif\".format(i))\n",
    "#             with rasterio.open(path, 'w', driver='GTiff', height=height, width=width, count=1, dtype='float32', crs='EPSG:4326', transform=transform) as dst:\n",
    "#                 # Write the data to the GeoTIFF\n",
    "#                 dst.write(flipped_final_disp_other, 1)\n",
    "    \n",
    "#         print(\"Storing other components as NetCDF\")\n",
    "#         # Create NetCDF file for other components\n",
    "#         output_nc_path_other = \"/gws/nopw/j04/nceo_geohazards_vol1/projects/COMET/eejap002/ica_data/all_iran/other_components_{}/{}/other_components.nc\".format(ncomponents, frame)\n",
    "    \n",
    "#         with nc.Dataset(output_nc_path_other, 'w') as file:\n",
    "#             # Create dimensions\n",
    "#             file.createDimension('time', restored_signals_3d[0].shape[0])  # Assuming all signals have the same time dimension\n",
    "#             file.createDimension('latitude', restored_signals_3d[0].shape[1])\n",
    "#             file.createDimension('longitude', restored_signals_3d[0].shape[2])\n",
    "#             component_dim = file.createDimension('component', len(restored_signals_3d) - 1)  # -1 to exclude the inelastic component\n",
    "    \n",
    "#             # Create variables\n",
    "#             time_var = file.createVariable('time', 'f4', ('time',))\n",
    "#             lat_var = file.createVariable('latitude', 'f4', ('latitude',))\n",
    "#             lon_var = file.createVariable('longitude', 'f4', ('longitude',))\n",
    "#             median_dominant_period_var = file.createVariable('median_dominant_period', 'f4')\n",
    "    \n",
    "#             # Create a variable for each other component\n",
    "#             component_vars = []\n",
    "#             for i in range(len(restored_signals_3d) - 1):\n",
    "#                 component_vars.append(file.createVariable(f'component_{i}', 'f4', ('time', 'latitude', 'longitude')))\n",
    "    \n",
    "#             # Add data to variables\n",
    "#             time_data_other = nc_data\n",
    "#             lat_data_other = lat\n",
    "#             lon_data_other = lon\n",
    "    \n",
    "#             # Assign data to variables\n",
    "#             time_var[:] = time_data_other\n",
    "#             lat_var[:] = lat_data_other\n",
    "#             lon_var[:] = lon_data_other\n",
    "    \n",
    "#             # Assign data for each other component to its respective variable\n",
    "#             non_inelastic_components = []\n",
    "#             non_inelastic_period = []\n",
    "#             for i, signal in enumerate(restored_signals_3d):\n",
    "#                 if i == max_index_in_median_r_squared:\n",
    "#                     continue  # Skip the inelastic component\n",
    "#                 non_inelastic_components.append(signal)\n",
    "#             for i, signal_data in enumerate(non_inelastic_components):\n",
    "#                 component_vars[i] = signal_data\n",
    "#             print('CVs', component_vars)\n",
    "#             for i, period in enumerate(median_dominant_period):\n",
    "#                 if i == max_index_in_median_r_squared:\n",
    "#                     continue\n",
    "#                 non_inelastic_period.append(period)\n",
    "#             for i, period_component in enumerate(non_inelastic_period):\n",
    "#                 median_dominant_period_var[i] = period_component\n",
    "        \n",
    "#         print(\"storing inelastic as netcdf\")\n",
    "#         # also save 3d inelastic dataset as nc\n",
    "#         with nc.Dataset(output_nc_path, 'w') as file:\n",
    "#             # Create dimensions\n",
    "#             file.createDimension('time', inelastic_signal.shape[0]) # 'None' allows for unlimited size along this dimension\n",
    "#             file.createDimension('latitude', inelastic_signal.shape[1])\n",
    "#             file.createDimension('longitude', inelastic_signal.shape[2])\n",
    "#             # Create variables\n",
    "#             time_var = file.createVariable('time', 'f4', ('time',))\n",
    "#             lat_var = file.createVariable('latitude', 'f4', ('latitude',))\n",
    "#             lon_var = file.createVariable('longitude', 'f4', ('longitude',))\n",
    "#             data_var = file.createVariable('data', 'f4', ('time', 'latitude', 'longitude'))\n",
    "#             # add data to variables\n",
    "#             time_data = nc_data\n",
    "#             lat_data = lat\n",
    "#             lon_data = lon\n",
    "#             data_data = inelastic_signal\n",
    "#             time_var[:] = time_data\n",
    "#             lat_var[:] = lat_data\n",
    "#             lon_var[:] = lon_data\n",
    "#             data_var[:] = data_data\n",
    "\n",
    "#     else:\n",
    "#         print(frame, 'has only', restored_signals[0].shape[1], 'coherent pixels')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambalics",
   "language": "python",
   "name": "mambalics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
